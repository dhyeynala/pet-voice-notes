Run black --check --diff .
  black --check --diff .
  shell: /usr/bin/bash -e {0}
  env:
    pythonLocation: /opt/hostedtoolcache/Python/3.11.13/x64
    PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.13/x64/lib/pkgconfig
    Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.13/x64
    Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.13/x64
    Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.13/x64
    LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.13/x64/lib
--- /home/runner/work/pet-voice-notes/pet-voice-notes/firestore_store.py	2025-08-09 21:50:07.310131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/firestore_store.py	2025-08-09 21:50:42.696832+00:00
@@ -8,43 +8,37 @@
 import os
 
 load_dotenv()
 if not firebase_admin._apps:
     cred = credentials.Certificate("gcloud-key.json")
-    firebase_admin.initialize_app(cred, {
-        "storageBucket": os.getenv("FIREBASE_STORAGE_BUCKET")
-    })
+    firebase_admin.initialize_app(cred, {"storageBucket": os.getenv("FIREBASE_STORAGE_BUCKET")})
 
 db = firestore.client()
+
 
 # Store voice transcript + summary
 def store_to_firestore(user_id, pet_id, transcript, summary):
-    db.collection("pets").document(pet_id).collection("voice-notes").add({
-        "transcript": transcript,
-        "summary": summary,
-        "timestamp": datetime.utcnow().isoformat()
-    })
+    db.collection("pets").document(pet_id).collection("voice-notes").add(
+        {"transcript": transcript, "summary": summary, "timestamp": datetime.utcnow().isoformat()}
+    )
+
 
 # Store PDF summary
 def store_pdf_summary(user_id, pet_id, summary, timestamp, file_name, file_url):
-    db.collection("pets").document(pet_id).collection("records").add({
-        "summary": summary,
-        "file_name": file_name,
-        "file_url": file_url,
-        "timestamp": timestamp
-    })
+    db.collection("pets").document(pet_id).collection("records").add(
+        {"summary": summary, "file_name": file_name, "file_url": file_url, "timestamp": timestamp}
+    )
+
 
 # Get pets linked to a user
 def get_pets_by_user_id(user_id):
     user_doc = db.collection("users").document(user_id).get()
     if not user_doc.exists:
         return []
     pet_ids = user_doc.to_dict().get("pets", [])
-    return [
-        {"id": pid, **db.collection("pets").document(pid).get().to_dict()}
-        for pid in pet_ids
-    ]
+    return [{"id": pid, **db.collection("pets").document(pid).get().to_dict()} for pid in pet_ids]
+
 
 # Get individual pet by ID
 def get_pet_by_id(pet_id):
     """Get individual pet data by pet ID"""
     try:
@@ -53,30 +47,31 @@
             return {"id": pet_id, **pet_doc.to_dict()}
         return None
     except Exception as e:
         print(f"Error getting pet by ID: {e}")
         return None
-        
+
 
 # Add a pet and sync it across user and page, with authorizedUsers and markdown
 def add_pet_to_page_and_user(user_id, pet_data, page_id):
     pet_name = pet_data.get("name", "")
     pet_id = pet_name.lower().replace(" ", "_").replace(".", "").replace(",", "")
-    
+
     # Create timestamp for breed_last_updated
     from datetime import datetime
+
     current_time = datetime.utcnow().isoformat()
-    
+
     # Create enhanced pet document
     pet_document = {
         "name": pet_name,
         "animal_type": pet_data.get("animal_type", ""),
         "breed": pet_data.get("breed", ""),
         "breed_last_updated": current_time,
-        "created_at": current_time
+        "created_at": current_time,
     }
-    
+
     # Add optional fields if provided
     if pet_data.get("age") is not None:
         pet_document["age"] = pet_data["age"]
     if pet_data.get("weight") is not None:
         pet_document["weight"] = pet_data["weight"]
@@ -85,22 +80,25 @@
 
     # Create or update pet
     db.collection("pets").document(pet_id).set(pet_document)
 
     # Link pet to user and page
-    db.collection("users").document(user_id).set({
-        "pets": firestore.ArrayUnion([pet_id]),
-        "pages": firestore.ArrayUnion([page_id])
-    }, merge=True)
-
-    db.collection("pages").document(page_id).set({
-        "pets": firestore.ArrayUnion([pet_id]),
-        "authorizedUsers": firestore.ArrayUnion([user_id]),
-        "markdown": ""  # initialized only if not set yet
-    }, merge=True)
-
-    return { "id": pet_id, "name": pet_name, **pet_document }
+    db.collection("users").document(user_id).set(
+        {"pets": firestore.ArrayUnion([pet_id]), "pages": firestore.ArrayUnion([page_id])}, merge=True
+    )
+
+    db.collection("pages").document(page_id).set(
+        {
+            "pets": firestore.ArrayUnion([pet_id]),
+            "authorizedUsers": firestore.ArrayUnion([user_id]),
+            "markdown": "",  # initialized only if not set yet
+        },
+        merge=True,
+    )
+
+    return {"id": pet_id, "name": pet_name, **pet_document}
+
 
 # Invite user by email and link to page
 def handle_user_invite(data):
     email = data["email"]
     page_id = data["pageId"]
@@ -113,106 +111,95 @@
     else:
         uid = str(uuid.uuid4())
         create_user_entry(uid, email)
 
     # Add user to page
-    db.collection("pages").document(page_id).set({
-        "authorizedUsers": firestore.ArrayUnion([uid])
-    }, merge=True)
+    db.collection("pages").document(page_id).set({"authorizedUsers": firestore.ArrayUnion([uid])}, merge=True)
 
     # Add page to user
-    db.collection("users").document(uid).set({
-        "pages": firestore.ArrayUnion([page_id])
-    }, merge=True)
+    db.collection("users").document(uid).set({"pages": firestore.ArrayUnion([page_id])}, merge=True)
 
     return {"status": "success", "userId": uid}
+
 
 # (Optional) Create blank user entry when invited
 def create_user_entry(uid, email):
-    db.collection("users").document(uid).set({
-        "email": email,
-        "pets": [],
-        "pages": []
-    })
+    db.collection("users").document(uid).set({"email": email, "pets": [], "pages": []})
+
 
 # Analytics helper functions
 def get_analytics_summary(pet_id, days=30):
     """Get analytics summary for a pet"""
     from collections import defaultdict
     from datetime import timedelta
-    
+
     cutoff_date = (datetime.utcnow() - timedelta(days=days)).isoformat()
-    results = db.collection("pets").document(pet_id).collection("analytics").where(
-        "timestamp", ">=", cutoff_date
-    ).stream()
-    
-    summary = defaultdict(lambda: {
-        "total": 0,
-        "this_week": 0,
-        "recent_entries": []
-    })
-    
+    results = db.collection("pets").document(pet_id).collection("analytics").where("timestamp", ">=", cutoff_date).stream()
+
+    summary = defaultdict(lambda: {"total": 0, "this_week": 0, "recent_entries": []})
+
     one_week_ago = datetime.utcnow() - timedelta(days=7)
-    
+
     for doc in results:
         data = doc.to_dict()
         category = data.get("category", "unknown")
         timestamp = datetime.fromisoformat(data.get("timestamp", ""))
-        
+
         summary[category]["total"] += 1
         summary[category]["recent_entries"].append(data)
-        
+
         if timestamp >= one_week_ago:
             summary[category]["this_week"] += 1
-    
+
     return dict(summary)
+
 
 # Store voice/text daily activities in analytics collection for dashboard visibility
 def store_analytics_from_voice(pet_id, transcript, summary, classification):
     """Store daily activity data from voice/text input into analytics collection"""
     try:
         # Map activity keywords to analytics categories
         keywords = classification.get('keywords', [])
         content_type = classification.get('classification', 'DAILY_ACTIVITY')
         confidence = classification.get('confidence', 0.8)
-        
+
         # Determine the most appropriate category based on keywords
         category_mapping = {
             'diet': ['food', 'eat', 'meal', 'breakfast', 'lunch', 'dinner', 'treat', 'feeding'],
             'exercise': ['walk', 'run', 'play', 'fetch', 'exercise', 'activity', 'training', 'park'],
             'sleep': ['sleep', 'nap', 'rest', 'tired', 'sleepy', 'bed'],
             'mood': ['happy', 'excited', 'calm', 'anxious', 'playful', 'mood', 'behavior'],
             'energy_levels': ['energy', 'active', 'lazy', 'lethargic', 'energetic', 'vigorous'],
             'grooming': ['bath', 'brush', 'groom', 'clean', 'nail', 'trim'],
             'bowel_movements': ['poop', 'bathroom', 'potty', 'bowel', 'outdoor'],
-            'social': ['social', 'friend', 'dog', 'cat', 'people', 'visitor']
+            'social': ['social', 'friend', 'dog', 'cat', 'people', 'visitor'],
         }
-        
+
         # Find best matching category
         best_category = 'daily_activity'  # default
         max_matches = 0
-        
+
         for category, category_keywords in category_mapping.items():
             matches = sum(1 for keyword in keywords if any(ck in keyword.lower() for ck in category_keywords))
             if matches > max_matches:
                 max_matches = matches
                 best_category = category
-        
+
         # Create analytics entry
         analytics_entry = {
             "category": best_category,
             "source": "voice_input",
             "transcript": transcript,
             "summary": summary,
             "classification_confidence": confidence,
             "keywords": keywords,
             "content_type": content_type,
             "timestamp": datetime.utcnow().isoformat(),
-            "notes": f"Daily activity recorded via voice/text: {summary[:100]}..."
+            "notes": f"Daily activity recorded via voice/text: {summary[:100]}...",
         }
-        
+
         # Store in analytics collection
         db.collection("pets").document(pet_id).collection("analytics").add(analytics_entry)
         print(f"✅ Stored daily activity as '{best_category}' in analytics collection")
-        
+
     except Exception as e:
         print(f"❌ Error storing voice analytics: {e}")
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/firestore_store.py
--- /home/runner/work/pet-voice-notes/pet-voice-notes/main.py	2025-08-09 21:50:07.311131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/main.py	2025-08-09 21:50:42.765844+00:00
@@ -1,6 +1,6 @@
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/main.py
-#main.py
+# main.py
 
 import os
 import argparse
 from dotenv import load_dotenv
 import openai
@@ -11,10 +11,11 @@
 # Load env variables
 load_dotenv()
 
 # Set OpenAI key
 openai.api_key = os.getenv("OPENAI_API_KEY")
+
 
 def main(user_id, pet_id):
     print(" Starting real-time voice notes system...")
 
     try:
@@ -36,19 +37,16 @@
         if classification.get('classification') == 'DAILY_ACTIVITY':
             store_analytics_from_voice(pet_id, transcript, summary, classification)
             print(" Daily activity data also stored to analytics.")
 
         # Return for FastAPI
-        return {
-            "transcript": transcript,
-            "summary": summary,
-            "classification": classification
-        }
+        return {"transcript": transcript, "summary": summary, "classification": classification}
 
     except Exception as e:
         print(f" Error: {e}")
         return {"error": str(e)}
+
 
 # CLI usage (safe to keep)
 if __name__ == "__main__":
     parser = argparse.ArgumentParser(description="Voice note system for pets.")
     parser.add_argument("--user_id", required=True, help="User ID for Firestore")
--- /home/runner/work/pet-voice-notes/pet-voice-notes/pdf_parser.py	2025-08-09 21:50:07.311131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/pdf_parser.py	2025-08-09 21:50:42.799621+00:00
@@ -1,16 +1,17 @@
-#pdf_parser.py
+# pdf_parser.py
 
 import fitz
 import os
 from openai import OpenAI
 from datetime import datetime
 from firestore_store import store_pdf_summary
 from dotenv import load_dotenv
 
 load_dotenv()
 client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
+
 
 def extract_text_and_summarize(file_path, user_id, pet_id, file_name, file_url):
     # Step 1: Extract PDF text
     doc = fitz.open(file_path)
     text = "\n".join([page.get_text() for page in doc])
@@ -25,15 +26,15 @@
                     "role": "system",
                     "content": (
                         "You are a veterinary assistant AI. Summarize this medical document. "
                         "Extract key points like symptoms, diagnosis, treatments, medications, and vet advice. "
                         "Keep it concise and useful for a pet health timeline."
-                    )
+                    ),
                 },
-                {"role": "user", "content": text[:12000]}
+                {"role": "user", "content": text[:12000]},
             ],
-            temperature=0.5
+            temperature=0.5,
         )
         summary = response.choices[0].message.content.strip()
     except Exception as e:
         print("OpenAI error:", e)
         summary = "Summary could not be generated due to OpenAI error."
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/pdf_parser.py
--- /home/runner/work/pet-voice-notes/pet-voice-notes/setup.py	2025-08-09 21:50:07.312131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/setup.py	2025-08-09 21:50:42.875154+00:00
@@ -8,43 +8,48 @@
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/setup.py
 import sys
 import subprocess
 import json
 from pathlib import Path
 
+
 def print_banner():
-    print("""
+    print(
+        """
 ╔══════════════════════════════════════════════════════════════╗
 ║                    🐾 PetPulse Setup                        ║
 ║                                                              ║
 ║  AI-Powered Pet Health Management System                    ║
 ║  Open Source Setup Script                                   ║
 ╚══════════════════════════════════════════════════════════════╝
-    """)
+    """
+    )
+
 
 def check_python_version():
     """Check if Python version is compatible"""
     if sys.version_info < (3, 8):
         print("❌ Python 3.8 or higher is required")
         sys.exit(1)
     print("✅ Python version check passed")
+
 
 def create_env_file():
     """Create .env file from template"""
     if os.path.exists('.env'):
         response = input("⚠️  .env file already exists. Overwrite? (y/N): ")
         if response.lower() != 'y':
             print("📝 Skipping .env creation")
             return
-    
+
     print("\n🔧 Setting up environment variables...")
-    
+
     # Get user inputs
     openai_key = input("Enter your OpenAI API Key: ").strip()
     dog_api_key = input("Enter your Dog API Key (optional): ").strip()
     cat_api_key = input("Enter your Cat API Key (optional): ").strip()
     google_project = input("Enter your Google Cloud Project ID: ").strip()
-    
+
     # Create .env content
     env_content = f"""# PetPulse Environment Configuration
 # Generated by setup script
 
 # OpenAI API Key - Get from https://platform.openai.com/api-keys
@@ -64,33 +69,34 @@
 # Security Notes:
 # - Never commit your actual .env file to version control!
 # - Keep your API keys secure and rotate them regularly
 # - See SECURITY.md for detailed security guidelines
 """
-    
+
     with open('.env', 'w') as f:
         f.write(env_content)
-    
+
     print("✅ .env file created successfully")
+
 
 def create_firebase_config():
     """Create Firebase configuration file"""
     if os.path.exists('public/firebase-config.js') and 'YOUR_FIREBASE_API_KEY' not in open('public/firebase-config.js').read():
         response = input("⚠️  Firebase config already exists. Overwrite? (y/N): ")
         if response.lower() != 'y':
             print("📝 Skipping Firebase config creation")
             return
-    
+
     print("\n🔥 Setting up Firebase configuration...")
-    
+
     # Get Firebase details
     firebase_api_key = input("Enter your Firebase Web API Key: ").strip()
     project_id = input("Enter your Firebase Project ID: ").strip()
     messaging_sender_id = input("Enter your Firebase Messaging Sender ID: ").strip()
     app_id = input("Enter your Firebase App ID: ").strip()
     measurement_id = input("Enter your Firebase Measurement ID (optional): ").strip()
-    
+
     # Create Firebase config
     firebase_config = f"""// Firebase Configuration
 // Generated by setup script
 
 import {{ initializeApp }} from "https://www.gstatic.com/firebasejs/10.12.2/firebase-app.js";
@@ -106,25 +112,27 @@
   measurementId: "{measurement_id}"
 }};
 
 export const app = initializeApp(firebaseConfig);
 """
-    
+
     with open('public/firebase-config.js', 'w') as f:
         f.write(firebase_config)
-    
+
     print("✅ Firebase configuration created successfully")
+
 
 def install_dependencies():
     """Install Python dependencies"""
     print("\n📦 Installing Python dependencies...")
     try:
         subprocess.run([sys.executable, '-m', 'pip', 'install', '-r', 'requirements.txt'], check=True)
         print("✅ Dependencies installed successfully")
     except subprocess.CalledProcessError:
         print("❌ Failed to install dependencies")
         print("💡 Try running: pip install -r requirements.txt manually")
+
 
 def create_google_cloud_instructions():
     """Create instructions for Google Cloud setup"""
     instructions = """
 🔑 Google Cloud Setup Instructions:
@@ -152,45 +160,47 @@
 ├── gcloud-key.json        (download from Google Cloud)
 ├── public/
 │   └── firebase-config.js (created by this script)
 └── ... (other files)
 """
-    
+
     with open('GOOGLE_CLOUD_SETUP.md', 'w') as f:
         f.write(instructions)
-    
+
     print("📝 Google Cloud setup instructions saved to GOOGLE_CLOUD_SETUP.md")
+
 
 def main():
     print_banner()
-    
+
     print("🚀 Welcome to PetPulse Setup!")
     print("This script will help you configure the project with your own API keys and project details.\n")
-    
+
     # Check Python version
     check_python_version()
-    
+
     # Create environment file
     create_env_file()
-    
+
     # Create Firebase config
     create_firebase_config()
-    
+
     # Install dependencies
     install_dependencies()
-    
+
     # Create setup instructions
     create_google_cloud_instructions()
-    
-    print("\n" + "="*60)
+
+    print("\n" + "=" * 60)
     print("🎉 Setup Complete!")
-    print("="*60)
+    print("=" * 60)
     print("\n📋 Next Steps:")
     print("1. Follow the instructions in GOOGLE_CLOUD_SETUP.md")
     print("2. Download your Google Cloud service account key as 'gcloud-key.json'")
     print("3. Run: python api_server.py")
     print("4. Open http://localhost:8000 in your browser")
     print("\n📚 For more help, see README.md and SECURITY.md")
-    print("="*60)
+    print("=" * 60)
+
 
 if __name__ == "__main__":
-    main() 
\ No newline at end of file
+    main()
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/ai_analytics.py
--- /home/runner/work/pet-voice-notes/pet-voice-notes/ai_analytics.py	2025-08-09 21:50:07.293131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/ai_analytics.py	2025-08-09 21:50:42.942894+00:00
@@ -18,21 +18,23 @@
 logger = logging.getLogger(__name__)
 
 # Set OpenAI API key
 openai.api_key = os.getenv("OPENAI_API_KEY")
 
+
 class PetAnalyticsAI:
     def __init__(self):
         self.client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
-    
-    def generate_daily_headlines(self, pet_name: str, daily_data: List[Dict], 
-                               historical_data: List[Dict] = None, date: str = None) -> List[str]:
+
+    def generate_daily_headlines(
+        self, pet_name: str, daily_data: List[Dict], historical_data: List[Dict] = None, date: str = None
+    ) -> List[str]:
         """Generate AI-powered daily routine headlines"""
         try:
             # Prepare context for AI
             context = self._prepare_analytics_context(pet_name, daily_data, historical_data, date)
-            
+
             prompt = f"""
             You are an expert pet health analyst creating engaging daily routine headlines for {pet_name}.
             
             Daily Activities Data:
             {json.dumps(context['daily_summary'], indent=2)}
@@ -53,45 +55,44 @@
             - "😴 Chill vibes: {pet_name} had a perfectly relaxed low-energy day"
             - "💊 Health hero: {pet_name} took all medications on schedule"
             
             Generate headlines as a JSON array of strings.
             """
-            
+
             response = self.client.chat.completions.create(
-                model="gpt-4",
-                messages=[{"role": "user", "content": prompt}],
-                temperature=0.7,
-                max_tokens=300
+                model="gpt-4", messages=[{"role": "user", "content": prompt}], temperature=0.7, max_tokens=300
             )
-            
+
             content = response.choices[0].message.content.strip()
-            
+
             # Try to parse as JSON, fallback to simple parsing
             try:
                 headlines = json.loads(content)
                 if isinstance(headlines, list):
                     return headlines[:5]  # Limit to 5 headlines
             except json.JSONDecodeError:
                 # Fallback: extract lines that look like headlines
                 lines = content.split('\n')
-                headlines = [line.strip().strip('"').strip("'") for line in lines 
-                           if line.strip() and any(emoji in line for emoji in ['🌟', '🍽️', '😴', '💊', '🏃', '⚡', '❤️', '🎾', '✨'])]
+                headlines = [
+                    line.strip().strip('"').strip("'")
+                    for line in lines
+                    if line.strip() and any(emoji in line for emoji in ['🌟', '🍽️', '😴', '💊', '🏃', '⚡', '❤️', '🎾', '✨'])
+                ]
                 return headlines[:5]
-            
+
         except Exception as e:
             logger.error(f"Error generating AI headlines: {e}")
             # Fallback to simple headlines
             return self._generate_fallback_headlines(pet_name, daily_data, date)
-        
+
         return self._generate_fallback_headlines(pet_name, daily_data, date)
-    
-    def generate_health_insights(self, pet_name: str, analytics_data: List[Dict], 
-                               timeframe_days: int = 30) -> Dict[str, Any]:
+
+    def generate_health_insights(self, pet_name: str, analytics_data: List[Dict], timeframe_days: int = 30) -> Dict[str, Any]:
         """Generate AI-powered health insights and recommendations"""
         try:
             context = self._prepare_health_context(pet_name, analytics_data, timeframe_days)
-            
+
             prompt = f"""
             You are a veterinary health analyst providing insights for {pet_name} based on {timeframe_days} days of health data.
             
             Health Data Summary:
             {json.dumps(context, indent=2)}
@@ -121,261 +122,256 @@
             - Energy level trends
             - Medication compliance
             - Any concerning patterns in bowel movements or behavior
             - Positive health behaviors to celebrate
             """
-            
+
             response = self.client.chat.completions.create(
-                model="gpt-4",
-                messages=[{"role": "user", "content": prompt}],
-                temperature=0.3,
-                max_tokens=500
+                model="gpt-4", messages=[{"role": "user", "content": prompt}], temperature=0.3, max_tokens=500
             )
-            
+
             content = response.choices[0].message.content.strip()
             insights = json.loads(content)
             return insights
-            
+
         except Exception as e:
             logger.error(f"Error generating health insights: {e}")
             return self._generate_fallback_insights(pet_name, analytics_data)
-    
-    def _prepare_analytics_context(self, pet_name: str, daily_data: List[Dict], 
-                                 historical_data: List[Dict] = None, date: str = None) -> Dict:
+
+    def _prepare_analytics_context(
+        self, pet_name: str, daily_data: List[Dict], historical_data: List[Dict] = None, date: str = None
+    ) -> Dict:
         """Prepare analytics context for AI processing"""
         # Categorize daily data
         categories = defaultdict(list)
         for entry in daily_data:
             category = entry.get('category', 'unknown')
             categories[category].append(entry)
-        
+
         # Create daily summary
         daily_summary = {}
         for category, entries in categories.items():
             if category == 'diet':
                 daily_summary['diet'] = {
                     'meal_count': len(entries),
                     'foods': [e.get('food', '') for e in entries],
-                    'meal_types': [e.get('type', '') for e in entries]
+                    'meal_types': [e.get('type', '') for e in entries],
                 }
             elif category == 'exercise':
                 total_duration = sum(int(e.get('duration', 0)) for e in entries)
                 daily_summary['exercise'] = {
                     'session_count': len(entries),
                     'total_duration': total_duration,
                     'types': [e.get('type', '') for e in entries],
-                    'avg_intensity': self._calculate_avg_intensity(entries)
+                    'avg_intensity': self._calculate_avg_intensity(entries),
                 }
             elif category == 'energy_levels':
                 levels = [int(e.get('level', 3)) for e in entries]
                 daily_summary['energy'] = {
                     'avg_level': np.mean(levels) if levels else 3,
                     'recordings': len(levels),
-                    'trend': self._calculate_energy_trend(levels)
+                    'trend': self._calculate_energy_trend(levels),
                 }
             elif category == 'medication':
                 daily_summary['medication'] = {
                     'doses_given': len(entries),
-                    'medications': [e.get('name', '') for e in entries]
-                }
-        
+                    'medications': [e.get('name', '') for e in entries],
+                }
+
         # Analyze historical patterns if available
         patterns = {}
         if historical_data:
             patterns = self._analyze_historical_patterns(historical_data)
-        
-        return {
-            'daily_summary': daily_summary,
-            'patterns': patterns,
-            'data_completeness': len(daily_data) > 0
-        }
-    
+
+        return {'daily_summary': daily_summary, 'patterns': patterns, 'data_completeness': len(daily_data) > 0}
+
     def _prepare_health_context(self, pet_name: str, analytics_data: List[Dict], timeframe_days: int) -> Dict:
         """Prepare health context for AI analysis"""
         categories = defaultdict(list)
         for entry in analytics_data:
             category = entry.get('category', 'unknown')
             categories[category].append(entry)
-        
+
         context = {
             'timeframe_days': timeframe_days,
             'total_entries': len(analytics_data),
-            'categories_tracked': list(categories.keys())
+            'categories_tracked': list(categories.keys()),
         }
-        
+
         # Analyze each category
         for category, entries in categories.items():
             if category == 'exercise':
                 durations = [int(e.get('duration', 0)) for e in entries]
                 context['exercise_analysis'] = {
                     'total_sessions': len(entries),
                     'avg_duration': np.mean(durations) if durations else 0,
                     'total_duration': sum(durations),
                     'consistency': len(entries) / timeframe_days,
-                    'types': list(Counter(e.get('type', '') for e in entries).keys())
-                }
-            
+                    'types': list(Counter(e.get('type', '') for e in entries).keys()),
+                }
+
             elif category == 'diet':
                 context['diet_analysis'] = {
                     'total_meals': len(entries),
                     'avg_meals_per_day': len(entries) / timeframe_days,
                     'variety': len(set(e.get('food', '') for e in entries)),
-                    'meal_types': list(Counter(e.get('type', '') for e in entries).keys())
-                }
-            
+                    'meal_types': list(Counter(e.get('type', '') for e in entries).keys()),
+                }
+
             elif category == 'energy_levels':
                 levels = [int(e.get('level', 3)) for e in entries]
                 context['energy_analysis'] = {
                     'avg_energy': np.mean(levels) if levels else 3,
                     'recordings': len(levels),
                     'high_energy_days': sum(1 for l in levels if l >= 4),
-                    'low_energy_days': sum(1 for l in levels if l <= 2)
-                }
-            
+                    'low_energy_days': sum(1 for l in levels if l <= 2),
+                }
+
             elif category == 'medication':
                 context['medication_analysis'] = {
                     'total_doses': len(entries),
                     'unique_medications': len(set(e.get('name', '') for e in entries)),
-                    'compliance_rate': len(entries) / timeframe_days  # Simplified
-                }
-            
+                    'compliance_rate': len(entries) / timeframe_days,  # Simplified
+                }
+
             elif category == 'bowel_movements':
                 consistencies = [e.get('consistency', 'normal') for e in entries]
                 context['bowel_analysis'] = {
                     'total_movements': len(entries),
                     'avg_per_day': len(entries) / timeframe_days,
                     'consistency_breakdown': dict(Counter(consistencies)),
-                    'normal_percentage': (consistencies.count('normal') / len(consistencies) * 100) if consistencies else 100
-                }
-        
+                    'normal_percentage': (consistencies.count('normal') / len(consistencies) * 100) if consistencies else 100,
+                }
+
         return context
-    
+
     def _calculate_avg_intensity(self, exercise_entries: List[Dict]) -> str:
         """Calculate average exercise intensity"""
         intensities = [e.get('intensity', 'moderate') for e in exercise_entries]
         intensity_map = {'low': 1, 'moderate': 2, 'high': 3}
         avg_value = np.mean([intensity_map.get(i, 2) for i in intensities])
-        
+
         if avg_value < 1.5:
             return 'low'
         elif avg_value < 2.5:
             return 'moderate'
         else:
             return 'high'
-    
+
     def _calculate_energy_trend(self, energy_levels: List[int]) -> str:
         """Calculate energy level trend"""
         if len(energy_levels) < 2:
             return 'stable'
-        
+
         trend = np.polyfit(range(len(energy_levels)), energy_levels, 1)[0]
         if trend > 0.1:
             return 'increasing'
         elif trend < -0.1:
             return 'decreasing'
         else:
             return 'stable'
-    
+
     def _analyze_historical_patterns(self, historical_data: List[Dict]) -> Dict:
         """Analyze historical patterns in pet data"""
         if not historical_data:
             return {}
-        
+
         # Convert to DataFrame for easier analysis
         df = pd.DataFrame(historical_data)
         df['timestamp'] = pd.to_datetime(df['timestamp'])
-        
+
         patterns = {}
-        
+
         # Analyze by category
         for category in df['category'].unique():
             category_data = df[df['category'] == category]
             patterns[category] = {
                 'frequency': len(category_data),
                 'most_active_hour': self._find_most_active_hour(category_data),
-                'weekday_pattern': self._analyze_weekday_pattern(category_data)
+                'weekday_pattern': self._analyze_weekday_pattern(category_data),
             }
-        
+
         return patterns
-    
+
     def _find_most_active_hour(self, category_data: pd.DataFrame) -> int:
         """Find the most active hour for a category"""
         if category_data.empty:
             return 12  # Default to noon
-        
+
         hours = category_data['timestamp'].dt.hour
         return hours.mode().iloc[0] if not hours.empty else 12
-    
+
     def _analyze_weekday_pattern(self, category_data: pd.DataFrame) -> Dict:
         """Analyze weekday patterns"""
         if category_data.empty:
             return {}
-        
+
         weekdays = category_data['timestamp'].dt.day_name()
         weekday_counts = weekdays.value_counts()
-        
+
         return {
             'most_active_day': weekday_counts.index[0] if not weekday_counts.empty else 'Monday',
-            'distribution': weekday_counts.to_dict()
+            'distribution': weekday_counts.to_dict(),
         }
-    
+
     def _generate_fallback_headlines(self, pet_name: str, daily_data: List[Dict], date: str) -> List[str]:
         """Generate simple fallback headlines when AI fails"""
         headlines = []
         categories = defaultdict(list)
-        
+
         for entry in daily_data:
             category = entry.get('category', 'unknown')
             categories[category].append(entry)
-        
+
         if categories.get('diet'):
             meal_count = len(categories['diet'])
             headlines.append(f"🍽️ {pet_name} enjoyed {meal_count} meal{'s' if meal_count != 1 else ''} today")
-        
+
         if categories.get('exercise'):
             total_duration = sum(int(e.get('duration', 0)) for e in categories['exercise'])
             if total_duration > 30:
                 headlines.append(f"🏃 Active day: {pet_name} exercised for {total_duration} minutes!")
-        
+
         if categories.get('energy_levels'):
             levels = [int(e.get('level', 3)) for e in categories['energy_levels']]
             avg_energy = sum(levels) / len(levels) if levels else 3
             if avg_energy >= 4:
                 headlines.append(f"⚡ High energy day for {pet_name}!")
             elif avg_energy <= 2:
                 headlines.append(f"😴 {pet_name} had a relaxed day")
-        
+
         if not headlines:
             headlines.append(f"📅 Another wonderful day in {pet_name}'s life!")
-        
+
         return headlines
-    
+
     def _generate_fallback_insights(self, pet_name: str, analytics_data: List[Dict]) -> Dict[str, Any]:
         """Generate simple fallback insights when AI fails"""
         categories = defaultdict(list)
         for entry in analytics_data:
             categories[entry.get('category', 'unknown')].append(entry)
-        
+
         insights = {
             "overall_health_score": 7,  # Default neutral score
             "key_insights": [],
             "recommendations": [],
             "alerts": [],
-            "positive_trends": []
+            "positive_trends": [],
         }
-        
+
         # Simple rule-based insights
         if categories.get('exercise'):
             total_sessions = len(categories['exercise'])
             if total_sessions >= 20:  # Over 30 days
                 insights["positive_trends"].append(f"{pet_name} maintains excellent exercise consistency")
             elif total_sessions < 5:
                 insights["recommendations"].append("Consider increasing exercise frequency")
-        
+
         if categories.get('diet'):
             if len(categories['diet']) > 60:  # More than 2 meals per day avg
                 insights["key_insights"].append("Good feeding routine established")
-        
+
         return insights
+
 
 # Service class exported for lazy initialization
 __all__ = ['PetAnalyticsAI']
--- /home/runner/work/pet-voice-notes/pet-voice-notes/intelligent_chatbot_service.py	2025-08-09 21:50:07.311131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/intelligent_chatbot_service.py	2025-08-09 21:50:43.034777+00:00
@@ -14,137 +14,131 @@
 
 from firestore_store import db, get_pet_by_id
 from visualization_service import PetVisualizationService
 from simple_rag_service import SimplePetHealthRAGService
 
+
 class IntelligentChatbotService:
     """Enhanced chatbot that uses OpenAI Function Calling for smart visualization decisions with data caching"""
-    
+
     def __init__(self):
         self.openai_client = openai.OpenAI()
         self.rag_service = SimplePetHealthRAGService()
         self.visualization_service = PetVisualizationService()
-        
+
         # Define available functions for OpenAI Function Calling
         self.available_functions = self._define_visualization_functions()
-        
+
         # Pet data cache to avoid repeated database queries
         self.pet_data_cache = {}
         self.cache_timestamps = {}
         self.cache_expiry_minutes = 30  # Cache expires after 30 minutes
-    
+
     def _is_cache_valid(self, pet_id: str) -> bool:
         """Check if cached data for pet is still valid"""
         if pet_id not in self.cache_timestamps:
             return False
-        
+
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/intelligent_chatbot_service.py
         cache_time = self.cache_timestamps[pet_id]
         expiry_time = cache_time + timedelta(minutes=self.cache_expiry_minutes)
         return datetime.utcnow() < expiry_time
-    
+
     async def preload_pet_data(self, pet_id: str, days: int = 30) -> Dict[str, Any]:
         """Preload and cache all pet data for efficient subsequent queries"""
         print(f"🔄 Preloading data for pet {pet_id} (last {days} days)")
-        
+
         try:
             cutoff_date = (datetime.utcnow() - timedelta(days=days)).isoformat()
-            
+
             # Get pet basic info
             pet_info = get_pet_by_id(pet_id)
-            
+
             # Get analytics data
-            analytics_query = db.collection("pets").document(pet_id).collection("analytics").where(
-                "timestamp", ">=", cutoff_date
+            analytics_query = (
+                db.collection("pets").document(pet_id).collection("analytics").where("timestamp", ">=", cutoff_date)
             )
-            
+
             analytics_data = []
             for doc in analytics_query.stream():
                 data = doc.to_dict()
                 analytics_data.append(data)
-            
+
             # Get voice notes
-            voice_query = db.collection("pets").document(pet_id).collection("voice-notes").where(
-                "timestamp", ">=", cutoff_date
+            voice_query = (
+                db.collection("pets").document(pet_id).collection("voice-notes").where("timestamp", ">=", cutoff_date)
             )
-            
+
             voice_notes = []
             for doc in voice_query.stream():
                 data = doc.to_dict()
                 data['id'] = doc.id
                 voice_notes.append(data)
-            
+
             # Get text inputs
-            text_query = db.collection("pets").document(pet_id).collection("textinput").where(
-                "timestamp", ">=", cutoff_date
-            )
-            
+            text_query = db.collection("pets").document(pet_id).collection("textinput").where("timestamp", ">=", cutoff_date)
+
             text_inputs = []
             for doc in text_query.stream():
                 data = doc.to_dict()
                 data['id'] = doc.id
                 text_inputs.append(data)
-            
+
             # Get medical records
-            records_query = db.collection("pets").document(pet_id).collection("records").where(
-                "timestamp", ">=", cutoff_date
-            )
-            
+            records_query = db.collection("pets").document(pet_id).collection("records").where("timestamp", ">=", cutoff_date)
+
             medical_records = []
             for doc in records_query.stream():
                 data = doc.to_dict()
                 data['id'] = doc.id
                 medical_records.append(data)
-            
+
             # Cache all data
             cached_data = {
                 "pet_info": pet_info,
                 "analytics_data": analytics_data,
                 "voice_notes": voice_notes,
                 "text_inputs": text_inputs,
                 "medical_records": medical_records,
                 "days": days,
-                "loaded_at": datetime.utcnow().isoformat()
+                "loaded_at": datetime.utcnow().isoformat(),
             }
-            
+
             self.pet_data_cache[pet_id] = cached_data
             self.cache_timestamps[pet_id] = datetime.utcnow()
-            
+
             print(f"✅ Cached data for pet {pet_id}:")
             print(f"   Analytics: {len(analytics_data)} entries")
-            print(f"   Voice Notes: {len(voice_notes)} entries") 
+            print(f"   Voice Notes: {len(voice_notes)} entries")
             print(f"   Text Inputs: {len(text_inputs)} entries")
             print(f"   Medical Records: {len(medical_records)} entries")
-            
+
             return {
                 "status": "success",
                 "message": f"Preloaded data for pet {pet_id}",
                 "data_summary": {
                     "analytics_entries": len(analytics_data),
                     "voice_notes": len(voice_notes),
                     "text_inputs": len(text_inputs),
                     "medical_records": len(medical_records),
                     "pet_name": pet_info.get('name', 'Unknown') if pet_info else 'Unknown',
-                    "cache_valid_until": (datetime.utcnow() + timedelta(minutes=self.cache_expiry_minutes)).isoformat()
-                }
+                    "cache_valid_until": (datetime.utcnow() + timedelta(minutes=self.cache_expiry_minutes)).isoformat(),
+                },
             }
-            
+
         except Exception as e:
             print(f"❌ Error preloading pet data: {e}")
-            return {
-                "status": "error",
-                "message": f"Failed to preload data: {str(e)}"
-            }
-    
+            return {"status": "error", "message": f"Failed to preload data: {str(e)}"}
+
     def get_cached_pet_data(self, pet_id: str) -> Optional[Dict]:
         """Get cached pet data if available and valid"""
         if self._is_cache_valid(pet_id):
             print(f"✅ Using cached data for pet {pet_id}")
             return self.pet_data_cache[pet_id]
         else:
             print(f"⚠️ No valid cache for pet {pet_id}")
             return None
-    
+
     def clear_pet_cache(self, pet_id: str = None):
         """Clear cache for specific pet or all pets"""
         if pet_id:
             if pet_id in self.pet_data_cache:
                 del self.pet_data_cache[pet_id]
@@ -152,11 +146,11 @@
                 print(f"🗑️ Cleared cache for pet {pet_id}")
         else:
             self.pet_data_cache.clear()
             self.cache_timestamps.clear()
             print("🗑️ Cleared all pet data cache")
-    
+
     def _define_visualization_functions(self) -> List[Dict]:
         """Define all available visualization functions for OpenAI Function Calling"""
         return [
             {
                 "type": "function",
@@ -166,16 +160,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_activity_energy_correlation",
@@ -183,16 +177,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_energy_distribution_chart",
@@ -200,16 +194,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_diet_frequency_chart",
@@ -217,16 +211,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_health_overview_chart",
@@ -234,16 +228,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_exercise_duration_histogram",
@@ -251,16 +245,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_behavior_mood_chart",
@@ -268,16 +262,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_social_interaction_chart",
@@ -285,16 +279,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_sleep_pattern_chart",
@@ -302,16 +296,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_medical_records_timeline",
@@ -319,16 +313,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_summary_metrics",
@@ -336,16 +330,16 @@
                     "parameters": {
                         "type": "object",
                         "properties": {
                             "reason": {
                                 "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["reason"]
-                    }
-                }
+                                "description": "Why this visualization would be helpful for the user's question",
+                            }
+                        },
+                        "required": ["reason"],
+                    },
+                },
             },
             {
                 "type": "function",
                 "function": {
                     "name": "generate_dynamic_chart",
@@ -354,85 +348,84 @@
                         "type": "object",
                         "properties": {
                             "chart_type": {
                                 "type": "string",
                                 "enum": ["line", "bar", "doughnut", "area", "scatter"],
-                                "description": "Type of chart to generate"
+                                "description": "Type of chart to generate",
                             },
                             "x_axis": {
-                                "type": "string", 
+                                "type": "string",
                                 "enum": ["date", "category", "hour", "day_of_week", "month"],
-                                "description": "X-axis data dimension"
+                                "description": "X-axis data dimension",
                             },
                             "y_axis": {
                                 "type": "string",
                                 "enum": ["count", "duration", "level", "value", "average"],
-                                "description": "Y-axis data dimension"
+                                "description": "Y-axis data dimension",
                             },
                             "filters": {
                                 "type": "object",
-                                "description": "Filters to apply to data (optional). Format: {'category': ['diet', 'exercise']}"
+                                "description": "Filters to apply to data (optional). Format: {'category': ['diet', 'exercise']}",
                             },
                             "aggregation": {
                                 "type": "string",
                                 "enum": ["count", "sum", "average", "max", "min"],
-                                "description": "How to aggregate the data"
+                                "description": "How to aggregate the data",
                             },
-                            "time_period": {
-                                "type": "integer",
-                                "description": "Number of days to look back (default: 30)"
+                            "time_period": {"type": "integer", "description": "Number of days to look back (default: 30)"},
+                            "group_by": {
+                                "type": "string",
+                                "enum": ["category", "date", "hour", "day_of_week"],
+                                "description": "Group data by this dimension for multi-series charts (optional)",
                             },
-                            "group_by": {
-                                "type": "string",
-                                "enum": ["category", "date", "hour", "day_of_week"],
-                                "description": "Group data by this dimension for multi-series charts (optional)"
+                            "reason": {
+                                "type": "string",
+                                "description": "Why this visualization would be helpful for the user's question",
                             },
-                            "reason": {
-                                "type": "string",
-                                "description": "Why this visualization would be helpful for the user's question"
-                            }
-                        },
-                        "required": ["chart_type", "x_axis", "y_axis", "reason"]
-                    }
-                }
-            }
+                        },
+                        "required": ["chart_type", "x_axis", "y_axis", "reason"],
+                    },
+                },
+            },
         ]
-    
+
     async def get_pet_analytics_data(self, pet_id: str, days: int = 30) -> List[Dict]:
         """Get analytics data for visualization (uses cache if available)"""
         try:
             # Try to get from cache first
             cached_data = self.get_cached_pet_data(pet_id)
             if cached_data and cached_data.get('days', 30) >= days:
                 print(f"📊 Using cached analytics data ({len(cached_data['analytics_data'])} entries)")
                 return cached_data['analytics_data']
-            
+
             # Fallback to database query if no cache
             print(f"🔍 Cache miss - querying database for pet {pet_id}")
             cutoff_date = (datetime.utcnow() - timedelta(days=days)).isoformat()
-            
-            analytics_query = db.collection("pets").document(pet_id).collection("analytics").where(
-                "timestamp", ">=", cutoff_date
+
+            analytics_query = (
+                db.collection("pets").document(pet_id).collection("analytics").where("timestamp", ">=", cutoff_date)
             )
-            
+
             analytics_data = []
             for doc in analytics_query.stream():
                 data = doc.to_dict()
                 analytics_data.append(data)
-            
+
             print(f"📊 Retrieved {len(analytics_data)} analytics entries from database")
             return analytics_data
         except Exception as e:
             print(f"Error getting analytics data: {e}")
             return []
-    
-    def _execute_visualization_function(self, function_name: str, analytics_data: List[Dict], function_args: Dict = None) -> Optional[Dict]:
+
+    def _execute_visualization_function(
+        self, function_name: str, analytics_data: List[Dict], function_args: Dict = None
+    ) -> Optional[Dict]:
         """Execute the specified visualization function with given data"""
         try:
             if function_args is None:
                 function_args = {}
-                
+
             if function_name == "generate_weekly_activity_chart":
                 return self.visualization_service.generate_weekly_activity_chart(analytics_data)
             elif function_name == "generate_activity_energy_correlation":
                 return self.visualization_service.generate_activity_energy_correlation(analytics_data)
             elif function_name == "generate_energy_distribution_chart":
@@ -460,50 +453,49 @@
                 y_axis = function_args.get('y_axis', 'count')
                 filters = function_args.get('filters', None)
                 aggregation = function_args.get('aggregation', 'count')
                 time_period = function_args.get('time_period', 30)
                 group_by = function_args.get('group_by', None)
-                
+
                 return self.visualization_service.generate_dynamic_chart(
-                    analytics_data, chart_type, x_axis, y_axis, 
-                    filters, aggregation, time_period, group_by
+                    analytics_data, chart_type, x_axis, y_axis, filters, aggregation, time_period, group_by
                 )
             else:
                 print(f"Unknown visualization function: {function_name}")
                 return None
         except Exception as e:
             print(f"Error executing visualization function {function_name}: {e}")
             return None
-    
+
     async def generate_intelligent_response(self, pet_id: str, query: str) -> Dict[str, Any]:
         """Generate intelligent response using OpenAI Function Calling for visualization decisions"""
-        
+
         # Try to use cached data for better performance
         cached_data = self.get_cached_pet_data(pet_id)
-        
+
         # Get RAG response first to provide context (pass cached data if available)
         if cached_data:
             print("🚀 Using cached data for RAG processing")
             rag_response = await self.rag_service.generate_rag_response_with_cache(pet_id, query, cached_data)
         else:
             print("🔍 No cache available - using standard RAG processing")
             rag_response = await self.rag_service.generate_rag_response(pet_id, query)
-        
+
         # Get pet information for context (from cache if available)
         if cached_data and cached_data.get('pet_info'):
             pet_data = cached_data['pet_info']
             print("✅ Using cached pet info")
         else:
             pet_data = get_pet_by_id(pet_id)
             print("🔍 Queried pet info from database")
-        
+
         pet_info = ""
         if pet_data:
             pet_info = f" for {pet_data.get('name', 'your pet')}"
             if pet_data.get('breed') and pet_data.get('animal_type'):
                 pet_info += f" (a {pet_data.get('breed')} {pet_data.get('animal_type')})"
-        
+
         # Create system prompt for function calling
         system_prompt = f"""You are a specialized Pet Health Assistant AI with access to comprehensive health data{pet_info}.
 
 You have access to visualization tools that can help users understand their pet's health data better. However, your PRIMARY goal is to provide helpful, accurate text responses based on the pet's health data.
 
@@ -550,95 +542,96 @@
 
         try:
             # Call OpenAI with function calling enabled
             response = self.openai_client.chat.completions.create(
                 model="gpt-4",
-                messages=[
-                    {"role": "system", "content": system_prompt},
-                    {"role": "user", "content": query}
-                ],
+                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": query}],
                 tools=self.available_functions,
                 tool_choice="auto",  # Let the model decide when to use tools
                 temperature=0.3,
-                max_tokens=800
+                max_tokens=800,
             )
-            
+
             # Process the response
             message = response.choices[0].message
-            
+
             # Prepare the base response
             base_response_text = message.content or ""
-            
+
             # If no text content but function calls were made, provide default text
             if not base_response_text and message.tool_calls:
                 base_response_text = "I'm analyzing your pet's data and preparing visualizations to help answer your question."
-            
+
             response_data = {
-            "status": "success",
+                "status": "success",
                 "response": base_response_text,
-            "sources": rag_response.get("sources", []),
-            "context_used": rag_response.get("context_used", False),
-            "timestamp": datetime.utcnow().isoformat(),
-                "function_calls_made": []
+                "sources": rag_response.get("sources", []),
+                "context_used": rag_response.get("context_used", False),
+                "timestamp": datetime.utcnow().isoformat(),
+                "function_calls_made": [],
             }
-            
+
             # Handle function calls if any were made
             if message.tool_calls:
                 print(f"🔧 OpenAI requested {len(message.tool_calls)} function call(s)")
-                
+
                 # Get analytics data once for all visualizations
                 analytics_data = await self.get_pet_analytics_data(pet_id)
                 print(f"📊 Retrieved {len(analytics_data)} analytics data points")
-            
+
                 visualizations = {}
-                
+
                 for tool_call in message.tool_calls:
                     function_name = tool_call.function.name
                     function_args = json.loads(tool_call.function.arguments)
-                    
+
                     print(f"🎯 Executing function: {function_name}")
                     print(f"   Reason: {function_args.get('reason', 'No reason provided')}")
-                    
+
                     # Execute the visualization function
                     if analytics_data:
                         chart_data = self._execute_visualization_function(function_name, analytics_data, function_args)
                         if chart_data:
                             visualizations[function_name] = chart_data
                             print(f"   ✅ Generated {function_name}")
                         else:
                             print(f"   ❌ Failed to generate {function_name}")
                     else:
                         print(f"   ❌ No analytics data available for {function_name}")
-                    
+
                     # Track function calls made
-                    response_data["function_calls_made"].append({
-                        "function": function_name,
-                        "reason": function_args.get('reason', 'No reason provided'),
-                        "success": function_name in visualizations
-                    })
-                
+                    response_data["function_calls_made"].append(
+                        {
+                            "function": function_name,
+                            "reason": function_args.get('reason', 'No reason provided'),
+                            "success": function_name in visualizations,
+                        }
+                    )
+
                 # Add visualizations to response if any were generated
                 if visualizations:
                     response_data["visualizations"] = visualizations
                     response_data["data_points"] = len(analytics_data)
                     print(f"✅ Added {len(visualizations)} visualizations to response")
-                
+
                     # Enhance the text response to mention the visualizations
                     if response_data["response"]:
-                        response_data["response"] += f"\n\n📊 I've also prepared {len(visualizations)} visualization(s) to help you better understand the data patterns."
+                        response_data[
+                            "response"
+                        ] += f"\n\n📊 I've also prepared {len(visualizations)} visualization(s) to help you better understand the data patterns."
                 else:
                     print("❌ No visualizations were generated despite function calls")
             else:
                 print("🔍 No function calls were made - providing text-only response")
-        
+
             return response_data
-            
+
         except Exception as e:
             print(f"Error in generate_intelligent_response: {e}")
             return {
                 "status": "error",
                 "response": f"I'm having trouble processing your request: {str(e)}",
                 "sources": rag_response.get("sources", []),
                 "context_used": rag_response.get("context_used", False),
                 "timestamp": datetime.utcnow().isoformat(),
-                "error": str(e)
-            } 
\ No newline at end of file
+                "error": str(e),
+            }
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/summarize_openai.py
--- /home/runner/work/pet-voice-notes/pet-voice-notes/summarize_openai.py	2025-08-09 21:50:07.313131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/summarize_openai.py	2025-08-09 21:50:43.105015+00:00
@@ -5,18 +5,19 @@
 import time
 
 load_dotenv()
 client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
 
+
 def summarize_text(text, max_retries=3):
     """
     Summarize text using OpenAI GPT-4o with intelligent context detection
     Handles MEDICAL concerns, DAILY ACTIVITIES, and MIXED content
     """
     if not text or len(text.strip()) == 0:
         return "No content to summarize"
-    
+
     # Enhanced system prompt for comprehensive pet care tracking
     system_prompt = """You are an intelligent pet care assistant AI that analyzes ALL aspects of pet life - both medical concerns and daily activities.
 
     Your task is to summarize pet-related voice notes or text input with intelligent context detection and appropriate tone.
     
@@ -59,54 +60,52 @@
     - **Mixed**: "Normal eating and enthusiastic play session in the yard, but owner noticed slight coughing during activity. Monitor respiratory symptoms and consider limiting strenuous exercise until assessed."
     - **Training**: "Successfully learned 'sit' and 'stay' commands during today's 15-minute training session. Responds well to positive reinforcement with treats. Ready to progress to more complex commands."
     - **Routine**: "Perfect morning routine: ate breakfast enthusiastically, enjoyed 20-minute walk, now relaxing in favorite sunny spot. Energy level appears normal and mood is content."
     
     Always provide helpful, accurate summaries that celebrate positive moments while taking health concerns seriously."""
-    
+
     for attempt in range(max_retries):
         try:
             response = client.chat.completions.create(
                 model="gpt-4o",
                 messages=[
+                    {"role": "system", "content": system_prompt},
                     {
-                        "role": "system",
-                        "content": system_prompt
+                        "role": "user",
+                        "content": f"Please analyze and summarize this pet note. Determine if it's medical, daily activity, or mixed content:\n\n{text[:4000]}",  # Limit to prevent token overflow
                     },
-                    {
-                        "role": "user", 
-                        "content": f"Please analyze and summarize this pet note. Determine if it's medical, daily activity, or mixed content:\n\n{text[:4000]}"  # Limit to prevent token overflow
-                    }
                 ],
                 temperature=0.3,
-                max_tokens=200
+                max_tokens=200,
             )
-            
+
             summary = response.choices[0].message.content.strip()
             print(f"✅ Summary generated: {summary[:100]}...")
             return summary
-            
+
         except Exception as e:
             print(f"❌ OpenAI API error (attempt {attempt + 1}/{max_retries}): {e}")
-            
+
             if attempt < max_retries - 1:
                 # Exponential backoff
-                wait_time = 2 ** attempt
+                wait_time = 2**attempt
                 print(f"⏳ Retrying in {wait_time} seconds...")
                 time.sleep(wait_time)
             else:
                 # Final fallback
                 return f"Unable to generate AI summary due to API error. Original text: {text[:200]}..."
-    
+
     return "Summary generation failed after multiple attempts."
+
 
 def summarize_pdf_text(pdf_text, max_retries=3):
     """
     Summarize PDF medical document text using OpenAI GPT-4o
     """
--- /home/runner/work/pet-voice-notes/pet-voice-notes/api_server.py	2025-08-09 21:50:07.293131+00:00
+++ /home/runner/work/pet-voice-notes/pet-voice-notes/api_server.py	2025-08-09 21:50:43.329155+00:00
@@ -1,6 +1,6 @@
would reformat /home/runner/work/pet-voice-notes/pet-voice-notes/api_server.py
-#api_server.py
+# api_server.py
 from fastapi import FastAPI, Request, UploadFile, File
 from fastapi.middleware.cors import CORSMiddleware
 from fastapi.staticfiles import StaticFiles
 from fastapi.responses import FileResponse
 from firebase_admin import storage
@@ -40,23 +40,29 @@
 _intelligent_chatbot_service = None
 _simple_rag_service = None
 _visualization_service = None
 _pet_ai = None
 
+
 def get_intelligent_chatbot_service():
     global _intelligent_chatbot_service
     if _intelligent_chatbot_service is None:
         from intelligent_chatbot_service import IntelligentChatbotService
+
         _intelligent_chatbot_service = IntelligentChatbotService()
     return _intelligent_chatbot_service
+
 
 def get_simple_rag_service():
     global _simple_rag_service
     if _simple_rag_service is None:
         from simple_rag_service import SimplePetHealthRAGService
+
         _simple_rag_service = SimplePetHealthRAGService()
     return _simple_rag_service
+
+
 def _require_gcp():
     """Ensure GCP is configured for endpoints that depend on it.
 
     Raises a 501 HTTP error if configuration is missing so tests and
     environments without secrets do not fail at import time.
@@ -67,23 +73,28 @@
         raise HTTPException(
             status_code=501,
             detail="GCP not configured. Set GOOGLE_CLOUD_PROJECT and credentials to use this endpoint.",
         )
 
+
 def get_visualization_service():
     global _visualization_service
     if _visualization_service is None:
         from visualization_service import PetVisualizationService
+
         _visualization_service = PetVisualizationService()
     return _visualization_service
+
 
 def get_pet_ai():
     global _pet_ai
     if _pet_ai is None:
         from ai_analytics import PetAnalyticsAI
+
         _pet_ai = PetAnalyticsAI()
     return _pet_ai
+
 
 app = FastAPI()
 
 app.add_middleware(
     CORSMiddleware,
@@ -91,47 +102,50 @@
     allow_credentials=True,
     allow_methods=["*"],
     allow_headers=["*"],
 )
 
+
 # ✅ Startup event to pre-warm critical services
 @app.on_event("startup")
 async def startup_event():
     """Pre-warm critical services to improve first request performance"""
     print("🚀 Starting PetPulse API server...")
     print("🔥 Pre-warming critical services...")
-    
+
     # Pre-warm only the most commonly used service (visualization)
     # to balance startup time vs first-request performance
     try:
         _ = get_visualization_service()
         print("✅ Visualization service pre-warmed")
     except Exception as e:
         print(f"⚠️ Failed to pre-warm visualization service: {e}")
-    
+
     print("🎉 PetPulse API server ready!")
+
 
 @app.post("/api/start")
 async def start(request: Request):
     data = await request.json()
     return run_main(data["uid"], data["pet"])
+
 
 @app.post("/api/upload_pdf")
 async def upload_pdf(request: Request, file: UploadFile = File(...)):
     # Guard: this endpoint depends on Google Cloud Storage & credentials
     _require_gcp()
     # Get form data
     form = await request.form()
     uid = form.get("uid")
     pet = form.get("pet")
-    
+
     if not uid or not pet:
         return {"error": "Missing uid or pet parameter"}
-    
+
     if not file.filename:
         return {"error": "No file provided"}
-    
+
     try:
         contents = await file.read()
         temp_path = f"/tmp/{file.filename}"
         with open(temp_path, "wb") as f:
             f.write(contents)
@@ -139,782 +153,765 @@
         blob = storage.bucket().blob(f"{uid}/{pet}/records/{uuid.uuid4()}_{file.filename}")
         blob.upload_from_filename(temp_path)
         blob.make_public()
 
         result = extract_text_and_summarize(temp_path, uid, pet, file.filename, blob.public_url)
-        
+
         # Clean up temporary file
         try:
             os.remove(temp_path)
         except:
             pass
-            
+
         if "error" in result:
             return {"error": result["error"]}
-            
+
         return {"message": "PDF processed", "summary": result["summary"], "url": blob.public_url}
-        
+
     except Exception as e:
         # Clean up temporary file on error
         try:
             os.remove(temp_path)
         except:
             pass
         return {"error": f"Failed to process PDF: {str(e)}"}
 
+
 @app.get("/api/user-pets/{user_id}")
 async def get_user_pets(user_id: str):
     return get_pets_by_user_id(user_id)
 
+
 @app.post("/api/pets/{user_id}")
 async def create_pet(user_id: str, request: Request):
     data = await request.json()
-    
+
     # Validate required fields
     if not data.get("name"):
         return {"error": "Pet name is required"}
     if not data.get("animal_type"):
         return {"error": "Animal type is required"}
-    
+
     try:
         result = add_pet_to_page_and_user(user_id, data, data.get("pageId", "default-page"))
         return {"status": "success", "pet": result}
     except Exception as e:
         return {"error": f"Failed to create pet: {str(e)}"}
+
 
 @app.post("/api/pages/invite")
 async def invite_user(request: Request):
     data = await request.json()
     return handle_user_invite(data)
 
+
 @app.get("/api/pages/{page_id}")
 async def get_page(page_id: str):
     doc = db.collection("pages").document(page_id).get()
     return doc.to_dict() or {}
 
+
 @app.post("/api/pages/{page_id}")
 async def update_page(page_id: str, request: Request):
     data = await request.json()
-    db.collection("pages").document(page_id).update({
-        "markdown": data.get("markdown", "")
-    })
+    db.collection("pages").document(page_id).update({"markdown": data.get("markdown", "")})
     return {"status": "updated"}
+
 
 @app.get("/api/markdown")
 async def get_markdown(page: str = None, pet: str = None):
     if not page or not pet:
         return {"markdown": ""}
-    
+
     page_doc = db.collection("pages").document(page).get()
     pet_doc = db.collection("pets").document(pet).get()
 
     pet_data = pet_doc.to_dict() or {}
     page_data = page_doc.to_dict() or {}
 
-    return {
-        "markdown": pet_data.get("markdown") or page_data.get("markdown", "")
-    }
+    return {"markdown": pet_data.get("markdown") or page_data.get("markdown", "")}
+
 
 @app.post("/api/markdown")
 async def update_markdown(request: Request):
     data = await request.json()
     page = data["page"]
     pet = data["pet"]
     markdown = data.get("markdown", "")
 
-    db.collection("pets").document(pet).set({ "markdown": markdown }, merge=True)
-    db.collection("pages").document(page).set({ "markdown": markdown }, merge=True)
-    return { "status": "updated" }
+    db.collection("pets").document(pet).set({"markdown": markdown}, merge=True)
+    db.collection("pages").document(page).set({"markdown": markdown}, merge=True)
+    return {"status": "updated"}
+
 
 # ✅ NEW: Add text input note under each pet
 @app.post("/api/pets/{pet_id}/textinput")
 async def add_pet_textinput(pet_id: str, request: Request):
     data = await request.json()
     input_text = data.get("input", "")
     if not input_text:
-        return { "status": "error", "message": "Input is empty" }
+        return {"status": "error", "message": "Input is empty"}
 
     # Enhanced: Classify and summarize the content
     from summarize_openai import summarize_text, classify_pet_content
-    
+
     # Classify the content type
     classification = classify_pet_content(input_text)
-    
+
     # Generate AI summary
     summary = summarize_text(input_text)
-    
+
     # Store with enhanced metadata
     entry_data = {
         "input": input_text,
         "summary": summary,
         "content_type": classification.get("classification", "MIXED"),
         "confidence": classification.get("confidence", 0.5),
         "keywords": classification.get("keywords", []),
-        "timestamp": datetime.utcnow().isoformat()
+        "timestamp": datetime.utcnow().isoformat(),
     }
-    
+
     db.collection("pets").document(pet_id).collection("textinput").add(entry_data)
 
     # If daily activity content, also store in analytics for dashboard visibility
     if classification.get('classification') == 'DAILY_ACTIVITY':
         from firestore_store import store_analytics_from_voice
+
         store_analytics_from_voice(pet_id, input_text, summary, classification)
         print(f"✅ Daily activity from text input also stored in analytics collection")
 
-    return { 
-        "status": "success", 
+    return {
+        "status": "success",
         "summary": summary,
         "content_type": classification.get("classification", "MIXED"),
         "confidence": classification.get("confidence", 0.5),
         "keywords": classification.get("keywords", []),
-        "message": f"Added {classification.get('classification', 'MIXED').lower()} note with AI summary"
+        "message": f"Added {classification.get('classification', 'MIXED').lower()} note with AI summary",
     }
+
 
 # ✅ NEW: Start recording endpoint
 @app.post("/api/start_recording")
 async def start_recording_endpoint(request: Request):
     data = await request.json()
     user_id = data.get("uid")
     pet_id = data.get("pet")
-    
+
     if not user_id or not pet_id:
         return {"status": "error", "message": "Missing uid or pet"}
-    
+
     result = start_recording()
     return result
+
 
 # ✅ NEW: Stop recording endpoint
 @app.post("/api/stop_recording")
 async def stop_recording_endpoint(request: Request):
     data = await request.json()
     user_id = data.get("uid")
     pet_id = data.get("pet")
-    
+
     if not user_id or not pet_id:
         return {"status": "error", "message": "Missing uid or pet"}
-    
+
     try:
         result = stop_recording()
-        
+
         # Handle the transcription result
         if result["status"] == "stopped" and result.get("transcript"):
             # We have a transcript, try to process with AI
             try:
                 from summarize_openai import summarize_text, classify_pet_content
-                
+
                 transcript = result["transcript"]
-                
+
                 # Classify the content type
                 classification = classify_pet_content(transcript)
-                
+
                 # Generate enhanced summary
                 summary = summarize_text(transcript)
-                
+
                 # Store with enhanced metadata
                 entry_data = {
                     "transcript": transcript,
                     "summary": summary,
                     "content_type": classification.get("classification", "MIXED"),
                     "confidence": classification.get("confidence", 0.5),
                     "keywords": classification.get("keywords", []),
-                    "timestamp": datetime.utcnow().isoformat()
+                    "timestamp": datetime.utcnow().isoformat(),
                 }
-                
+
                 db.collection("pets").document(pet_id).collection("voice-notes").add(entry_data)
-                
+
                 return {
                     "status": "success",
                     "transcript": transcript,
                     "summary": summary,
                     "content_type": classification.get("classification", "MIXED"),
                     "confidence": classification.get("confidence", 0.5),
-                    "message": f"Processed {classification.get('classification', 'MIXED').lower()} voice note"
+                    "message": f"Processed {classification.get('classification', 'MIXED').lower()} voice note",
                 }
-                
+
             except Exception as ai_error:
                 print(f"AI processing failed: {ai_error}")
                 # AI processing failed, but we still have transcript
                 # Store basic transcript without AI enhancement
                 entry_data = {
                     "transcript": result["transcript"],
                     "summary": "Transcription completed. AI processing unavailable.",
                     "content_type": "TRANSCRIPTION_ONLY",
-                    "timestamp": datetime.utcnow().isoformat()
+                    "timestamp": datetime.utcnow().isoformat(),
                 }
-                
+
                 db.collection("pets").document(pet_id).collection("voice-notes").add(entry_data)
-                
+
                 return {
                     "status": "stopped",
                     "transcript": result["transcript"],
-                    "message": "Transcription successful, AI processing unavailable"
+                    "message": "Transcription successful, AI processing unavailable",
                 }
-        
+
         elif result["status"] == "stopped":
             # Recording stopped but no transcript (no speech detected)
-            return {
-                "status": "stopped",
-                "message": "Recording stopped but no speech was detected"
-            }
-        
+            return {"status": "stopped", "message": "Recording stopped but no speech was detected"}
+
         else:
             # Recording failed or other error
-            return {
-                "status": "error",
-                "message": result.get("message", "Recording failed")
-            }
-            
+            return {"status": "error", "message": result.get("message", "Recording failed")}
+
     except Exception as e:
         print(f"Error in stop_recording_endpoint: {e}")
-        return {
-            "status": "error", 
-            "message": f"Server error: {str(e)}"
-        }
+        return {"status": "error", "message": f"Server error: {str(e)}"}
+
 
 # ✅ NEW: Get recording status endpoint
 @app.get("/api/recording_status")
 async def recording_status_endpoint():
     return get_recording_status()
 
+
 # ✅ Enhanced Analytics endpoints for comprehensive pet tracking
 @app.post("/api/pets/{pet_id}/analytics/{category}")
 async def add_analytics_entry(pet_id: str, category: str, request: Request):
     data = await request.json()
-    
+
     # Validate category
     valid_categories = [
-        "diet", "activity", "medication", "grooming", "exercise", 
-        "energy_levels", "bowel_movements", "exit_events", "weight", 
-        "temperature", "mood", "sleep", "water_intake"
+        "diet",
+        "activity",
+        "medication",
+        "grooming",
+        "exercise",
+        "energy_levels",
+        "bowel_movements",
+        "exit_events",
+        "weight",
+        "temperature",
+        "mood",
+        "sleep",
+        "water_intake",
     ]
-    
+
     if category not in valid_categories:
         return {"status": "error", "message": "Invalid category"}
-    
+
     # Add timestamp and store in Firestore
-    entry_data = {
-        **data,
-        "timestamp": datetime.utcnow().isoformat(),
-        "category": category
-    }
-    
+    entry_data = {**data, "timestamp": datetime.utcnow().isoformat(), "category": category}
+
     db.collection("pets").document(pet_id).collection("analytics").add(entry_data)
-    
+
     return {"status": "success", "data": entry_data}
+
 
 @app.get("/api/pets/{pet_id}/analytics")
 async def get_analytics_data(pet_id: str, category: str = None, days: int = 30):
     """Get analytics data including voice recordings for dashboard charts"""
     query = db.collection("pets").document(pet_id).collection("analytics")
-    
+
     if category:
         query = query.where("category", "==", category)
-    
-                'responsive': True,
-                'plugins': {
-                    'legend': {
-                        'display': False
+                'datasets': [
+                    {
+                        'label': 'Meal Count',
+                        'data': values,
+                        'backgroundColor': [
+                            self.chart_colors['success'],
+                            self.chart_colors['info'],
+                            self.chart_colors['warning'],
+                            self.chart_colors['purple'],
+                            self.chart_colors['teal'],
+                            self.chart_colors['pink'],
+                        ][: len(values)],
+                        'borderRadius': 8,
+                        'borderSkipped': False,
                     }
-                },
-                'scales': {
-                    'y': {
-                        'beginAtZero': True,
-                        'ticks': {
-                            'stepSize': 1
-                        }
-                    }
-                }
-            }
-        }
-    
+                ],
+            },
+            'options': {
+                'responsive': True,
+                'plugins': {'legend': {'display': False}},
+                'scales': {'y': {'beginAtZero': True, 'ticks': {'stepSize': 1}}},
+            },
+        }
+
     def generate_health_overview_chart(self, analytics_data: List[Dict]) -> Dict[str, Any]:
         """Generate health metrics overview radar chart"""
         categories = ['diet', 'exercise', 'medication', 'grooming', 'energy_levels', 'daily_activity']
         category_counts = defaultdict(int)
-        
+
         for entry in analytics_data:
             category = entry.get('category', '')
             if category in categories:
                 category_counts[category] += 1
-        
+
         # Normalize scores (0-10 scale based on activity frequency)
         max_count = max(category_counts.values()) if category_counts.values() else 1
         labels = ['Diet', 'Exercise', 'Medication', 'Grooming', 'Energy Tracking', 'Daily Activities']
         values = []
-        
+
         for category in categories:
             count = category_counts[category]
             # Scale to 0-10, with 5 as average
             score = min(10, (count / max_count) * 10) if max_count > 0 else 0
             values.append(round(score, 1))
-        
+
         if not labels or not values or sum(values) == 0:
             return None
 
         return {
             'type': 'radar',
             'data': {
                 'labels': labels,
-                'datasets': [{
-                    'label': 'Health Tracking Score',
-                    'data': values,
-                    'borderColor': self.chart_colors['primary'],
-                    'backgroundColor': self.chart_colors['primary'] + '30',
-                    'pointBackgroundColor': self.chart_colors['primary'],
-                    'pointBorderColor': '#ffffff',
-                    'pointHoverBackgroundColor': '#ffffff',
-                    'pointHoverBorderColor': self.chart_colors['primary']
-                }]
-            },
-            'options': {
-                'responsive': True,
-                'plugins': {
-                    'legend': {
-                        'display': False
+                'datasets': [
+                    {
+                        'label': 'Health Tracking Score',
+                        'data': values,
+                        'borderColor': self.chart_colors['primary'],
+                        'backgroundColor': self.chart_colors['primary'] + '30',
+                        'pointBackgroundColor': self.chart_colors['primary'],
+                        'pointBorderColor': '#ffffff',
+                        'pointHoverBackgroundColor': '#ffffff',
+                        'pointHoverBorderColor': self.chart_colors['primary'],
                     }
-                },
-                'scales': {
-                    'r': {
-                        'beginAtZero': True,
-                        'max': 10,
-                        'ticks': {
-                            'stepSize': 2
-                        }
-                    }
-                }
-            }
-        }
-    
+                ],
+            },
+            'options': {
+                'responsive': True,
+                'plugins': {'legend': {'display': False}},
+                'scales': {'r': {'beginAtZero': True, 'max': 10, 'ticks': {'stepSize': 2}}},
+            },
+        }
+
     def generate_exercise_duration_histogram(self, analytics_data: List[Dict]) -> Dict[str, Any]:
         """Generate exercise duration histogram including daily activities"""